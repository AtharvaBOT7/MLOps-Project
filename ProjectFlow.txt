--------------------------------Setting up the project structure--------------------------------

1. Install cookiecutter using
    >> pip install cookiecutter
2.  Run the following command in your terminal to get a project structure template:
    >> cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science
3. Remove the project named folder after copying the folders and files in your main local project directory.
4. Rename src.models to src.model


--------------------------------Setting up MLFlow on Dagshub--------------------------------
5. Go to Dagshub dashboard on the internet.
6. Create a new repository and connect that repo to your github repository. 
    >> Create -> New Repo -> Connect a repo (Github) -> Connect -> Select the repo -> Connect
7. Added the IMDB.csv dataset to the notebooks folder

-------------------------Setup MLFlow on Dagshub---------------------------
8. Go to: https://dagshub.com/dashboard
9. Create > New Repo > Connect a repo > (Github) Connect > Select your repo > Connect
10. Copy experiment tracking url and code snippet. (Also try: Go To MLFlow UI)
11. pip install dagshub & mlflow

12. Run the exp notebooks
13. git add - commit - push

14. dvc init
15. create a local folder as "local_s3" (temporary work)
16. on terminal - "dvc remote add -d mylocal local_s3"

17. Add code to below files/folders inside src dir:
    - logger
    - data_ingestion.py
    - data_preprocessing.py
    - feature_engineering.py
    - model_building.py
    - model_evaluation.py
    - register_model.py
18. add file - dvc.yaml (till model evaluation.metrics)
19. add file - params.yaml
20. DVC pipeline is ready to run - dvc repro
21. Once do - dvc status
22. git add - commit - push
